{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train shape: (146811, 2)\nVal shape: (62918, 2)\nTest shape: (60427, 2)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('/home/ken/shopee_ws/sentiment/dataraw/train.csv')\n",
    "val_df = pd.read_csv('/home/ken/shopee_ws/sentiment/dataraw/val.csv')\n",
    "test_df = pd.read_csv('/home/ken/shopee_ws/sentiment/dataraw/test.csv')\n",
    "\n",
    "train_df.drop('review_id', axis=1, inplace=True)\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Val shape:', val_df.shape)\n",
    "print('Test shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji  # https://pypi.org/project/emoji/\n",
    "\n",
    "have_emoji_train_idx = []\n",
    "\n",
    "have_emoji_val_idx = []\n",
    "have_emoji_test_idx = []\n",
    "\n",
    "for idx, review in enumerate(train_df['review']):\n",
    "    if any(char in emoji.UNICODE_EMOJI for char in review):\n",
    "        have_emoji_train_idx.append(idx)\n",
    "        \n",
    "for idx, review in enumerate(val_df['review']):\n",
    "    if any(char in emoji.UNICODE_EMOJI for char in review):\n",
    "        have_emoji_val_idx.append(idx)\n",
    "        \n",
    "for idx, review in enumerate(test_df['review']):\n",
    "    if any(char in emoji.UNICODE_EMOJI for char in review):\n",
    "        have_emoji_test_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train data has 20048 rows that used emoji, that means 13.66 percent of the total\nVal data has 8518 rows that used emoji, that means 13.54 percent of the total\nTest data has 7582 rows that used emoji, that means 12.55 percent of the total\n"
    }
   ],
   "source": [
    "train_emoji_percentage = round(len(have_emoji_train_idx) / train_df.shape[0] * 100, 2)\n",
    "print(f'Train data has {len(have_emoji_train_idx)} rows that used emoji, that means {train_emoji_percentage} percent of the total')\n",
    "\n",
    "val_emoji_percentage = round(len(have_emoji_val_idx) / val_df.shape[0] * 100, 2)\n",
    "print(f'Val data has {len(have_emoji_val_idx)} rows that used emoji, that means {val_emoji_percentage} percent of the total')\n",
    "\n",
    "test_emoji_percentage = round(len(have_emoji_test_idx) / test_df.shape[0] * 100, 2)\n",
    "print(f'Test data has {len(have_emoji_test_idx)} rows that used emoji, that means {test_emoji_percentage} percent of the total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_cleaning(text):\n",
    "    \n",
    "    # Change emoji to text\n",
    "    text = emoji.demojize(text).replace(\":\", \" \")\n",
    "    \n",
    "    # Delete repeated emoji\n",
    "    tokenizer = text.split()\n",
    "    repeated_list = []\n",
    "    \n",
    "    for word in tokenizer:\n",
    "        if word not in repeated_list:\n",
    "            repeated_list.append(word)\n",
    "    \n",
    "    text = ' '.join(text for text in repeated_list)\n",
    "    text = text.replace(\"_\", \" \").replace(\"-\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original = train_df.copy()\n",
    "val_df_original = val_df.copy()\n",
    "test_df_original = test_df.copy()\n",
    "\n",
    "# emoji_cleaning\n",
    "train_df.loc[have_emoji_train_idx, 'review'] = train_df.loc[have_emoji_train_idx, 'review'].apply(emoji_cleaning)\n",
    "\n",
    "val_df.loc[have_emoji_val_idx, 'review'] = val_df.loc[have_emoji_val_idx, 'review'].apply(emoji_cleaning)\n",
    "\n",
    "test_df.loc[have_emoji_test_idx, 'review'] = test_df.loc[have_emoji_test_idx, 'review'].apply(emoji_cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "34    It was frustrating seeing order but not receiv...\n42    Looks used. Seller claims cannot get ðŸ’¯ perfect...\n69    Very disappointed, the message that comes even...\nName: review, dtype: object"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_df_original.loc[have_emoji_train_idx, 'review'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "34    It was frustrating seeing order but not receiv...\n42    Looks used. Seller claims cannot get hundred p...\n69    Very disappointed, the message that comes even...\nName: review, dtype: object"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_df.loc[have_emoji_train_idx, 'review'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_cleaning(text):\n",
    "    import re\n",
    "    # delete lowercase and newline\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    \n",
    "    # change emoticon to text\n",
    "    text = re.sub(r':\\(', 'dislike', text)\n",
    "    text = re.sub(r': \\(\\(', 'dislike', text)\n",
    "    text = re.sub(r':, \\(', 'dislike', text)\n",
    "    text = re.sub(r':\\)', 'smile', text)\n",
    "    text = re.sub(r';\\)', 'smile', text)\n",
    "    text = re.sub(r':\\)\\)\\)', 'smile', text)\n",
    "    text = re.sub(r':\\)\\)\\)\\)\\)\\)', 'smile', text)\n",
    "    text = re.sub(r'=\\)\\)\\)\\)', 'smile', text)\n",
    "    \n",
    "    # delete punctuation\n",
    "    text = re.sub('[^a-z0-9 ]', ' ', text)\n",
    "    \n",
    "    tokenizer = text.split()\n",
    "    \n",
    "    return ' '.join([text for text in tokenizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(review_cleaning)\n",
    "val_df['review'] = val_df['review'].apply(review_cleaning)\n",
    "test_df['review'] = test_df['review'].apply(review_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_rows_train = []\n",
    "repeated_rows_val = []\n",
    "repeated_rows_test = []\n",
    "import re\n",
    "for idx, review in enumerate(train_df['review']):\n",
    "    if re.match(r'\\w*(\\w)\\1+', review):\n",
    "        repeated_rows_train.append(idx)\n",
    "        \n",
    "\n",
    "for idx, review in enumerate(val_df['review']):\n",
    "    if re.match(r'\\w*(\\w)\\1+', review):\n",
    "        repeated_rows_val.append(idx)\n",
    "        \n",
    "for idx, review in enumerate(test_df['review']):\n",
    "    if re.match(r'\\w*(\\w)\\1+', review):\n",
    "        repeated_rows_test.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total 43139 rows in train set\nTotal 18500 rows in val set\nTotal 10674 rows in test set\n"
    }
   ],
   "source": [
    "print(f'Total {len(repeated_rows_train)} rows in train set')\n",
    "print(f'Total {len(repeated_rows_val)} rows in val set')\n",
    "print(f'Total {len(repeated_rows_test)} rows in test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_repeated_char(text):\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[repeated_rows_train, 'review'] = train_df.loc[repeated_rows_train, 'review'].apply(delete_repeated_char)\n",
    "val_df.loc[repeated_rows_val, 'review'] = val_df.loc[repeated_rows_val, 'review'].apply(delete_repeated_char)\n",
    "test_df.loc[repeated_rows_test, 'review'] = test_df.loc[repeated_rows_test, 'review'].apply(delete_repeated_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noisy_row = [31, 50, 2235, 5244, 10409, 11748, 12384, 14395, 15215, 17629, 20819, 23691, 32089, 39532, 40530, 43954, 48186, 50500, 55834, 60088,\n",
    "             60442, 61095, 62982, 63803, 67464, 70791, 74861, 73636, 74119, 76275, 79789, 85745, 91058, 91663, 91800, 93204, 99295, 100903, 101177, 103155,\n",
    "             109166, 109566, 109651, 109724, 110115, 110441, 111461, 113175, 115782, 116903, 118099, 118328, 118414, 119071, 125338, 125340, 129496, 129640, \n",
    "             132027, 138212, 131626, 134715, 133248, 136217, 141377, 143707, 145045, 146485, 37301]\n",
    "\n",
    "train_df.drop(noisy_row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_shortened_words(text):\n",
    "    \n",
    "    # put \\b (boundary) for avoid the characters in the word to be replaced\n",
    "    # I only make a few examples here, you can add if you're interested :)\n",
    "    \n",
    "    text = re.sub(r'\\bapaa\\b', 'apa', text)\n",
    "    \n",
    "    text = re.sub(r'\\bbsk\\b', 'besok', text)\n",
    "    text = re.sub(r'\\bbrngnya\\b', 'barangnya', text)\n",
    "    text = re.sub(r'\\bbrp\\b', 'berapa', text)\n",
    "    text = re.sub(r'\\bbgt\\b', 'banget', text)\n",
    "    text = re.sub(r'\\bbngt\\b', 'banget', text)\n",
    "    text = re.sub(r'\\bgini\\b', 'begini', text)\n",
    "    text = re.sub(r'\\bbrg\\b', 'barang', text)\n",
    "    \n",
    "    text = re.sub(r'\\bdtg\\b', 'datang', text)\n",
    "    text = re.sub(r'\\bd\\b', 'di', text)\n",
    "    text = re.sub(r'\\bsdh\\b', 'sudah', text)\n",
    "    text = re.sub(r'\\bdri\\b', 'dari', text)\n",
    "    text = re.sub(r'\\bdsni\\b', 'disini', text)\n",
    "    \n",
    "    text = re.sub(r'\\bgk\\b', 'gak', text)\n",
    "    \n",
    "    text = re.sub(r'\\bhrs\\b', 'harus', text)\n",
    "    \n",
    "    text = re.sub(r'\\bjd\\b', 'jadi', text)\n",
    "    text = re.sub(r'\\bjg\\b', 'juga', text)\n",
    "    text = re.sub(r'\\bjgn\\b', 'jangan', text)\n",
    "    \n",
    "    text = re.sub(r'\\blg\\b', 'lagi', text)\n",
    "    text = re.sub(r'\\blgi\\b', 'lagi', text)\n",
    "    text = re.sub(r'\\blbh\\b', 'lebih', text)\n",
    "    text = re.sub(r'\\blbih\\b', 'lebih', text)\n",
    "    \n",
    "    text = re.sub(r'\\bmksh\\b', 'makasih', text)\n",
    "    text = re.sub(r'\\bmna\\b', 'mana', text)\n",
    "    \n",
    "    text = re.sub(r'\\borg\\b', 'orang', text)\n",
    "    \n",
    "    text = re.sub(r'\\bpjg\\b', 'panjang', text)\n",
    "    \n",
    "    text = re.sub(r'\\bka\\b', 'kakak', text)\n",
    "    text = re.sub(r'\\bkk\\b', 'kakak', text)\n",
    "    text = re.sub(r'\\bklo\\b', 'kalau', text)\n",
    "    text = re.sub(r'\\bkmrn\\b', 'kemarin', text)\n",
    "    text = re.sub(r'\\bkmrin\\b', 'kemarin', text)\n",
    "    text = re.sub(r'\\bknp\\b', 'kenapa', text)\n",
    "    text = re.sub(r'\\bkcil\\b', 'kecil', text)\n",
    "    \n",
    "    text = re.sub(r'\\bgmn\\b', 'gimana', text)\n",
    "    text = re.sub(r'\\bgmna\\b', 'gimana', text)\n",
    "    \n",
    "    text = re.sub(r'\\btp\\b', 'tapi', text)\n",
    "    text = re.sub(r'\\btq\\b', 'thanks', text)\n",
    "    text = re.sub(r'\\btks\\b', 'thanks', text)\n",
    "    text = re.sub(r'\\btlg\\b', 'tolong', text)\n",
    "    text = re.sub(r'\\bgk\\b', 'tidak', text)\n",
    "    text = re.sub(r'\\bgak\\b', 'tidak', text)\n",
    "    text = re.sub(r'\\bgpp\\b', 'tidak apa apa', text)\n",
    "    text = re.sub(r'\\bgapapa\\b', 'tidak apa apa', text)\n",
    "    text = re.sub(r'\\bga\\b', 'tidak', text)\n",
    "    text = re.sub(r'\\btgl\\b', 'tanggal', text)\n",
    "    text = re.sub(r'\\btggl\\b', 'tanggal', text)\n",
    "    text = re.sub(r'\\bgamau\\b', 'tidak mau', text)\n",
    "    \n",
    "    text = re.sub(r'\\bsy\\b', 'saya', text)\n",
    "    text = re.sub(r'\\bsis\\b', 'sister', text)\n",
    "    text = re.sub(r'\\bsdgkan\\b', 'sedangkan', text)\n",
    "    text = re.sub(r'\\bmdh2n\\b', 'semoga', text)\n",
    "    text = re.sub(r'\\bsmoga\\b', 'semoga', text)\n",
    "    text = re.sub(r'\\bsmpai\\b', 'sampai', text)\n",
    "    text = re.sub(r'\\bnympe\\b', 'sampai', text)\n",
    "    text = re.sub(r'\\bdah\\b', 'sudah', text)\n",
    "    \n",
    "    text = re.sub(r'\\bberkali2\\b', 'repeated', text)\n",
    "    \n",
    "    text = re.sub(r'\\byg\\b', 'yang', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/home/ken/shopee_ws/sentiment/clean_data/train.csv',index = False)\n",
    "val_df.to_csv('/home/ken/shopee_ws/sentiment/clean_data/val.csv',index = False)\n",
    "test_df.to_csv('/home/ken/shopee_ws/sentiment/clean_data/test.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595392575983",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}