{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "very nice thank you smiling_face_with_smiling_eyes\n[nltk_data] Downloading package stopwords to /home/ken/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "nltk.download('stopwords')\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "class TextTokenizer():\n",
    "    \"\"\"\n",
    "        Preprocess an input sentence, output new sentence\n",
    "\n",
    "        *preprocess_steps: list\n",
    "            None : Normal split sentence by space\n",
    "            \"base\" : consists of to lower, remove punctuations, remove stopwords\n",
    "            \"stem\" : Snollball Stem words in sentence\n",
    "            \"lemmatize\" : Lemmatize words in sentence\n",
    "            \"remove_emojis\" : Remove emojis from sentence\n",
    "            \"ngrams\" : Add bigrams, trigrams to output tokens\n",
    "            \"replace_consecutive\" : Trim off consecutive part in sentence\n",
    "            \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, preprocess_steps = None, max_length = None):\n",
    "\n",
    "        self.max_length = max_length\n",
    "        if preprocess_steps is not None:\n",
    "            assert isinstance(preprocess_steps, list) , \"preprocess_steps must be a list contains name of methods\"\n",
    "        self.preprocess_steps = preprocess_steps\n",
    "        \n",
    "        if preprocess_steps is not None:\n",
    "            if \"base\" in preprocess_steps:\n",
    "                self.punctuations = string.punctuation\n",
    "                self.stopwords_list = stopwords.words(\"english\")\n",
    "            if \"stem\" in preprocess_steps:\n",
    "                self.stemmer = SnowballStemmer('english')\n",
    "            if \"lemmatize\" in preprocess_steps:\n",
    "                self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        tokens = sentence.split()\n",
    "        if self.preprocess_steps is not None:\n",
    "            tokens = self.clean(tokens, self.preprocess_steps)\n",
    "        if self.max_length is not None:\n",
    "            tokens = tokens[:self.max_length]\n",
    "        tokens = \" \".join(tokens)\n",
    "        return tokens\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        if tokens in self.stopwords_list:\n",
    "            return ''\n",
    "        else:\n",
    "            return tokens\n",
    "    \n",
    "    def add_n_grams(self, tokens):\n",
    "        l = []\n",
    "        if \"2grams\" in self.preprocess_steps or \"ngrams\" in self.preprocess_steps:\n",
    "            bigrams = ngrams(tokens, 2)\n",
    "            for i in bigrams:\n",
    "                l.append(\" \".join(i))\n",
    "        if \"3grams\" in self.preprocess_steps or \"ngrams\" in self.preprocess_steps:\n",
    "            trigrams = ngrams(tokens, 3)\n",
    "            for j in trigrams:\n",
    "                l.append(\" \".join(j))\n",
    "    \n",
    "        return l\n",
    "\n",
    "    def replace_consecutive(self, sentence):\n",
    "        sentence = re.sub(r\"(.)\\1+\", r\"\\1\\1\", sentence)\n",
    "        return sentence\n",
    "\n",
    "    def extract_emojis(self, sentence):\n",
    "        plain_text = []\n",
    "        emo = []\n",
    "        for c in sentence:\n",
    "            if c not in emoji.UNICODE_EMOJI:\n",
    "                plain_text.append(c)\n",
    "            else:\n",
    "                tmp = emoji.demojize(c)\n",
    "                emo.append(tmp[1:len(tmp)-1])\n",
    "        plain_text = \"\".join(plain_text)\n",
    "        return plain_text, emo\n",
    "\n",
    "    def remove_punctuations(self, sentence):\n",
    "        result = \"\".join([w if w not in self.punctuations and not w.isdigit() else \"\" for w in sentence])\n",
    "        return result\n",
    "\n",
    "    def word_lowercase(self, sentence):\n",
    "        return sentence.lower()\n",
    "\n",
    "    def word_stemmer(self, sentence):\n",
    "        sentence = self.stemmer.stem(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def clean(self, tokens, types):\n",
    "        results = []\n",
    "        emo_lst = set()\n",
    "        for tok in tokens:\n",
    "            tok, emos = self.extract_emojis(tok)  \n",
    "            for emo in emos:\n",
    "                emo_lst.add(emo)\n",
    "            if \"base\" in types or \"lower\" in types:\n",
    "                tok = self.word_lowercase(tok)\n",
    "            \n",
    "            if \"base\" in types or \"remove_punctuaions\" in types:\n",
    "                tok = self.remove_punctuations(tok)\n",
    "                if tok == '':\n",
    "                        pass\n",
    "            \n",
    "            if \"stem\" in types:\n",
    "                tok = self.word_stemmer(tok)\n",
    "            \n",
    "            if \"replace_consecutive\" in types:\n",
    "                tok = self.replace_consecutive(tok)\n",
    "            \n",
    "            if (tok is not None) and (not tok.isspace()) and (tok!= ''): \n",
    "                results.append(tok)  \n",
    "\n",
    "                \n",
    "        grams = self.add_n_grams(results) if \"ngrams\" in types else []\n",
    "        results = results + grams\n",
    "        results = results + list(emo_lst)   \n",
    "        if len(results) == 0:\n",
    "            results.append('NaN')\n",
    "        return results\n",
    "    \n",
    "simple_tokenizer = TextTokenizer([\"base\", \"replace_consecutive\"])\n",
    "print(simple_tokenizer.tokenize('Very nice. Thank you ðŸ˜Š'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../extra_data/test_raw.csv')\n",
    "test[\"review\"] = test[\"review\"].apply(lambda text: simple_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../extra_data/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../extra_data/raw.csv')\n",
    "df = df.rename(columns={\"text\": \"review\", \"label\": \"rating\"})\n",
    "df.drop(df[df['rating']=='label'].index, inplace = True) # del noise row\n",
    "\n",
    "train = pd.read_csv('../extra_data/train.csv')\n",
    "train = train.drop(['review_id'], axis = 1)\n",
    "#1502574\n",
    "df = pd.concat([df, train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].astype(str)\n",
    "df['rating'] = df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Total  Percentage\nreview      6        0.01\nrating      0        0.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>review</th>\n      <td>6</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>0</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "def missing_value_of_data(data):\n",
    "    total=data.isnull().sum().sort_values(ascending=False)\n",
    "    percentage=round(total/data.shape[0]*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "missing_value_of_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Total  Percentage\n0  149378       35.97\n1  133351       32.11\n2  132524       31.91",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>149378</td>\n      <td>35.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133351</td>\n      <td>32.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>132524</td>\n      <td>31.91</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "count_values_in_column(df,'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Columns  Duplicate count\n0  rating          1616701\n1  review            85396",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Columns</th>\n      <th>Duplicate count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rating</td>\n      <td>1616701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>review</td>\n      <td>85396</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "def duplicated_values_data(data):\n",
    "    dup=[]\n",
    "    columns=data.columns\n",
    "    for i in data.columns:\n",
    "        dup.append(sum(data[i].duplicated()))\n",
    "    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])\n",
    "duplicated_values_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Columns  Duplicate count\n0  rating          1616701\n1  review                0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Columns</th>\n      <th>Duplicate count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rating</td>\n      <td>1616701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>review</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['review'])\n",
    "duplicated_values_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   rating                                             review\n0       5  looks ok not like so durable will hv to use a ...\n1       5  tried the current can be very powerful dependi...\n2       5  item received after a week looks smaller than ...\n3       5  thanks works as describe no complaints not rea...\n4       5  fast delivery considering itâ€™s from overseas a...\n5       5                         fast delivery good service\n6       5  got my order and it came well packaged have ye...\n7       5  items received in a nice box have not used it ...\n8       5  received in good condition tried so far so goo...\n9       1  item doesnâ€™t work asked me to send a refund sh...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>looks ok not like so durable will hv to use a ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>tried the current can be very powerful dependi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>item received after a week looks smaller than ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>thanks works as describe no complaints not rea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>fast delivery considering itâ€™s from overseas a...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>fast delivery good service</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>got my order and it came well packaged have ye...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5</td>\n      <td>items received in a nice box have not used it ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>received in good condition tried so far so goo...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>item doesnâ€™t work asked me to send a refund sh...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(lambda text: simple_tokenizer.tokenize(text))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.copy()\n",
    "df_merge = df.copy()\n",
    "df_trunc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trunc.drop(df_trunc[df_trunc['rating']==5].index[:1345447 - 143994 ], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Total  Percentage\n4  133351       32.11\n5  132524       31.91\n3   77159       18.58\n1   42050       10.13\n2   30169        7.27",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>133351</td>\n      <td>32.11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>132524</td>\n      <td>31.91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>77159</td>\n      <td>18.58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42050</td>\n      <td>10.13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30169</td>\n      <td>7.27</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "count_values_in_column(df_trunc,'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['rating'] = np.where(df_merge.rating < 4, 0, df_merge.rating)\n",
    "df_merge['rating'] = np.where(df_merge.rating == 4, 1, df_merge.rating)\n",
    "df_merge['rating'] = np.where(df_merge.rating == 5, 2, df_merge.rating)\n",
    "df_merge.drop(df_merge[df_merge['rating']==2].index[:1345447 - 143994 ], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Total  Percentage\n0  149378       35.97\n1  133351       32.11\n2  132524       31.91",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>149378</td>\n      <td>35.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133351</td>\n      <td>32.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>132524</td>\n      <td>31.91</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "count_values_in_column(df_merge,'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../extra_data/extra_full.csv',index=False)\n",
    "df_merge.to_csv('../extra_data/extra_merge.csv',index=False)\n",
    "df_trunc.to_csv('../extra_data/extra_small.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596212850679",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}